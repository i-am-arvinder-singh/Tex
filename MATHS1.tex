\documentclass[12pt,a4paper]{article}% 

\usepackage[a4paper,margin=1in]{geometry}
\usepackage{kbordermatrix}
\usepackage{amsmath}
\usepackage{pgfplots}
\usepackage{mathptmx}
\usepackage{mathtools}
\usepackage{blindtext}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage{textcomp}
\usepackage[noend]{algorithmic}
\usepackage{listings}
	\lstset{
		frame=tb, % draw a frame at the top and bottom of the code block
		tabsize=4, % tab space width
		showstringspaces=false, % don't mark spaces in strings
		numbers=left, % display line numbers on the left
		commentstyle=\color{green}, % comment color
		keywordstyle=\color{blue}, % keyword color
		stringstyle=\color{red} % string color
	}

\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\usepackage{pgfplots,amsmath}
\pgfplotsset{compat=1.12}



\newcommand{\TITLE}[1]{\item[#1]}
\renewcommand{\algorithmiccomment}[1]{$/\!/$ \parbox[t]{4.5cm}{\raggedright #1}}
\newbox\fixbox
\renewcommand{\algorithmicdo}{\setbox\fixbox\hbox{\ {} }\hskip-\wd\fixbox}
\newcommand{\algcost}[2]{\strut\hfill\makebox[1.5cm][l]{#1}\makebox[4cm][l]{#2}}
\usetikzlibrary{arrows,automata,positioning}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{calc}

\pgfmathsetseed{3}
\newcommand*{\Comb}[2]{{}^{#1}C_{#2}}

\begin{document}
	
	
	\begin{titlepage}
	\title{\includegraphics[width=0.38 \textwidth]{./NIT_Silchar_logo.png}\\\textbf{\large NATIONAL INSTITUTE OF TECHNOLOGY, SILCHAR}\\\textbf{{\large Department of Mathematics}}\\\bigskip {\large Project Report on,}\\\bigskip\textbf{{\normalsize "RANDOM WALK AND PROPERTIES ASSOCIATED WITH IT SUCH AS MEAN, VARIANCE, AUTO-CORRELATION FUNCTION, AUTO-COVARIANCE FUNCTION AND ITS ONE STEP TRANSITION PROBABILITIES. PERFORMING CHECKS FOR MARKOV CHAIN. DISCUSSION OF 'GAMBLER'S RUIN PROBLEM' WITH EXAMPLES" }}}
	\author{Subject : Mathematics-IV (MA-$202$)\\\\ Submitted by,\\Name : Arvinder Singh\\Scholar ID : 18-1-5-126\\B.Tech 4th SEM (CSE)}
	\date{\today}
	\clearpage\maketitle
	\thispagestyle{empty}
	\end{titlepage}
	
	\begin{center}
		\textbf{\large ABSTRACT}
	\end{center}
    \begin{flushleft}
    	\fontsize{12pt}{18pt}\selectfont
    	 In this project, I have given a concise overview of the mathematical analysis of the concept of 'simple random walk'. The various properties of this random or stochastic process is discussed in full detail.\\\smallskip
    	 Graphical visualization is given for better understanding and intuition. Definitions of various subject matters are given as and when required with proper citing of the equations that are used throughout the project.\\\smallskip
    	 This project was developed using open source software \LaTeX.
	\end{flushleft}
	
	\pagebreak
	\tableofcontents
	\cleardoublepage
	\section{Introduction}\label{sec:intro}
	\begin{flushleft}
		A \textit{random walk} is a discrete time \textit{stochastic} or \textit{random} process, with discrete time random variable, which can be denoted as the following:
		\begin{equation}
			X_{0},X_{1},X_{2},...
		\end{equation}
		A \textit{random process} is a time-varying function that assigns the	outcome of a random experiment to each time instant $X_{t}$.The above is also sometimes called a $1$-\textit{dimensional} simple random variable.\\
		Let us now define a independent identically distributed random variable $Y_{i}$ as follows:
		\[
		Y_{i}= 
		\begin{cases}
		1,& \text{with probability } \frac{1}{2}\\
		-1,              & \text{with probability } \frac{1}{2}
		\end{cases}
		\]
		If $P(Y_{i})$ denotes the probability of $Y_{i}$ taking a particular value then it can also be defined as the following:
		\begin{equation}
			P(Y_{i}=1) = \dfrac{1}{2}, P(Y_{i}=-1) = \dfrac{1}{2}
		\end{equation}
		As I have already mentioned that \textit{random walk} is a \textit{discrete time-parameter} stochastic process, with discrete random variables taking values by the following equation,
		\begin{equation}
			X_{t} = \sum_{\mathclap{i=1}}^{t} Y_{i}\enspace , \enspace X_{0}=0
		\end{equation}
		We can plot the above equation with $t$ taken in $X-axis$ and $X_{t}$ taken in $Y-axis$.
	\end{flushleft}
	\begin{center}
		\begin{tikzpicture}
		
		% Coordinate axes
		\begin{scope}[
		semithick,
		->,
		>={Stealth[]},
		]
		\draw (0, -5.5) -- (0, 5.5);
		\draw (0, 0) -- (9.5, 0);
		\end{scope}
		
		% Ticks
		\draw[node font=\small]
		\foreach \y in {-5, ..., 5} {
			(0, \y) +(.25em, 0) -- ++(-.25em, 0)
			node[left] {$\y$}
		}
		\foreach \y in {1, ..., 9} {
			(\y, 0) +(0, 0.25em) -- ++(0, -.25em)
			node[above,yshift=-.56cm] {$\y$}
		}
		
		(9.5, 0) node[right] {$t$}
		(0, 5.5) node[above] {$X_{t}$}
	
		;
		
		% Random walk
		\draw[dotted,line width = 0.35mm]
		(0, 0) -- (1,1)
		(0, 0) -- (1,-1)
		;
		\end{tikzpicture}
		\\\textbf{Figure 1}: This figure shows all probable directions in which the event $X_{1}$ can turn out to be.
	\end{center}
		
	\pagebreak
	\begin{flushleft}
		Suppose the event in the '\textbf{Figure 1}' turns out as follows:
	\end{flushleft}
	\begin{center}
		\begin{tikzpicture}
		
		% Coordinate axes
		\begin{scope}[
		semithick,
		->,
		>={Stealth[]},
		]
		\draw (0, -4.5) -- (0, 4.5);
		\draw (0, 0) -- (9.5, 0);
		\end{scope}
		
		% Ticks
		\draw[node font=\small]
		\foreach \y in {-4, ..., 4} {
			(0, \y) +(.25em, 0) -- ++(-.25em, 0)
			node[left] {$\y$}
		}
		\foreach \y in {1, ..., 9} {
			(\y, 0) +(0, 0.25em) -- ++(0, -.25em)
			node[above,yshift=-.56cm] {$\y$}
		}
		(9.5, 0) node[right] {$t$}
		(0, 4.5) node[above] {$X_{t}$}
		;
		
		% Random walk
		\draw[dotted,line width = 0.35mm]
		(1, 1) -- (2,2)
		(1, 1) -- (2,0)
		;
		\draw[thick]
		(0, 0) -- (1,1)
		;
		\end{tikzpicture}
		\\\textbf{Figure 2}: This figure shows all probable directions in which the event $X_{2}$ can turn out, we can observe that it solely depends upon $X_{1}$.
	\end{center}
	\begin{flushleft}
		This gives us enough intuition to develop an example for random walk. One such example is given below:
	\end{flushleft}
	\begin{center}
		\begin{tikzpicture}
		
		% Coordinate axes
		\begin{scope}[
		semithick,
		->,
		>={Stealth[]},
		]
		\draw (0, -4.5) -- (0, 4.5);
		\draw (0, 0) -- (9.5, 0);
		\end{scope}
		
		% Ticks
		\draw[node font=\small]
		\foreach \y in {-4, ..., 4} {
			(0, \y) +(.25em, 0) -- ++(-.25em, 0)
			node[left] {$\y$}
		}
		\foreach \y in {1, ..., 9} {
			(\y, 0) +(0, 0.25em) -- ++(0, -.25em)
			node[above,yshift=-.56cm] {$\y$}
		}
		(9.5, 0) node[right] {$t$}
		(0, 4.5) node[above] {$X_{t}$}
		;
		
		% Random walk
		\draw[dotted,line width = 0.35mm]
		(5, -1) -- (6,0)
		(5, -1) -- (6,-2)
		;
		\draw[thick]
		(0, 0) -- (1,1)
		(1, 1) -- (2,0)
		(2, 0) -- (3,-1)
		(3, -1) -- (4,0)
		(4, 0) -- (5,-1)
		;
		\end{tikzpicture}
		\\\textbf{Figure 3}: This figure shows one of many possible outcomes.
	\end{center}
	\begin{flushleft}
		We have seen visually and understood the intuition of how this process develops. We now try to understand why this process is called \textit{'Random Walk'}.\\
		If we take a look at the projection of the \textbf{Figure 3}, about $X-axis$ it is not interesting as it only progresses in one direction, on the other hand the projection of it about $Y-axis$ is interesting.\\
		It basically oscillates randomly back and forth. It is like someone walking randomly on a one dimensional path changing directions. Hence, it is named so.
	\end{flushleft}
	\section{Theory and Properties}
	\begin{flushleft}
		The event $Y_{i}$ as represented by equation $(2)$ can be an event such as : Picking a \textit{red} or a \textit{blue} ball from a covered box containing \textit{two} ball among which one is \textit{red} and the other is \textit{blue}, rolling a \textit{dice} and the outcome to be an \textit{even} or a \textit{odd} number, tossing a coin and outcome to be either \textit{heads} or \textit{tails},etc.\\
		Here we demonstrate with the help of a table how an example graph such as the one already shown in the \textbf{Figure 3} can be constructed. Here, we consider the first example (\textit{red and blue ball}) of the event $Y_{i}$ \textit{(again, it is independent identically distributed)} and generalize the probability as $p$ and $q$ as shown below. We have, $p+q=1$
		\begin{equation}
				Y_{i}= 
			\begin{cases}
			1,& \text{if the ball drawn is blue(B), probability=}p\\
			-1,& \text{if the ball drawn is red(R), \enspace probability=}q
			\end{cases}
		\end{equation}
		\begin{table}[ht]
			\centering % used for centering table
			\begin{tabular}{c c c c c c c c c c c c} % centered columns (4 columns)
				\hline %inserts double horizontal lines
				$t$ & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\ [0.5ex] % inserts table
				%heading
				\hline % inserts single horizontal line
				$Draw$ & & $R$ & $R$ & $B$ & $R$ & $B$ & $B$ & $R$ & $B$ & $B$  \\ % inserting body of the table
				$Y_{t}$ & $0$ & $-1$ & $-1$ & $1$ & $-1$ & $1$ & $1$ & $-1$ & $1$ & $1$  \\
				$X_{t}$ & $0$ & $-1$ & $-2$ & $-1$ & $-2$ & $-1$ & $0$ & $-1$ & $0$ & $1$ \\ [1ex] % [1ex] adds vertical space
				\hline %inserts single line
			\end{tabular}
			\caption{Table depicting each draw $Y_{t}$ and state $X_{t}$} 
		\end{table}
	\begin{center}
		\begin{tikzpicture}
		
		% Coordinate axes
		\begin{scope}[
		semithick,
		->,
		>={Stealth[]},
		]
		\draw (0, -4.5) -- (0, 4.5);
		\draw (0, 0) -- (10.5, 0);
		\end{scope}
		
		% Ticks
		\draw[node font=\small]
		\foreach \y in {-4, ..., 4} {
			(0, \y) +(.25em, 0) -- ++(-.25em, 0)
			node[left] {$\y$}
		}
		\foreach \y in {1, ..., 10} {
			(\y, 0) +(0, 0.25em) -- ++(0, -.25em)
			node[above,yshift=-.56cm] {$\y$}
		}
		(10.5, 0) node[right] {$t$}
		(0, 4.5) node[above] {$X_{t}$}
		;
		
		% Random walk
		\draw[dotted,line width = 0.35mm]
		(9, 1) -- (10,2)
		(9, 1) -- (10,0)
		;
		\draw[thick]
		(0, 0) -- (1,-1)
		(1, -1) -- (2,-2)
		(2,-2) -- (3,-1)
		(3, -1) -- (4,-2)
		(4, -2) -- (5,-1)
		(5, -1) -- (6,0)
		(6, 0) -- (7,-1)
		(7, -1) -- (8,0)
		(8, 0) -- (9,1)
		;
		\end{tikzpicture}
		\\\textbf{Figure 4}: This figure depicts the values taken by $X_{t}$ for set of outcomes as shown in the table.
	\end{center}
	\end{flushleft}
	\pagebreak
	We can now conclude that the sate space of random variable $X_{t}$ is discrete and take the values belonging to the following set:\\
	\begin{equation}
		S={\{...,-3,-2,-1,0,1,2,3,...\}}
	\end{equation}
	We also develop a recursive function for the random process $X_{t}$ for an event as an example \textit{equation} $(4)$.\\
	Using \textit{equation} $3$ we have,
	\begin{equation}
		X_{t} = Y_{t} + \sum_{\mathclap{i=1}}^{t-1} Y_{i}
	\end{equation} 
	\begin{equation}
		\implies X_{t} = Y_{t} + X_{t-1}, (From\enspace 3)
	\end{equation}
	\textit{equation} $7$ is defined for $t \geq 1$. Also, $X_{0}=0$ as already defined.\\Also, here this \textit{simple random walk} is said to be unrestricted, as there is no boundary condition on the values possible for $X_{t}$.
	\subsection{Probability Distribution}
	Here we basically try to develop a model that can give us probability for different values of $X_{t}$.\\
	We use the same notation as described in \textit{equation} $(2)$, except that we generalize it for value \textit{i}. In other words we find the value of,\\
	\begin{equation}
		P(X_{t}=i)
	\end{equation}
	The above can be read as, "Probability that $X_{t}=i$ at time $t$".\\\smallskip
	Definitely,
	\begin{center}
		$X_{t}\leq t$\\
		$\implies X_{t}=i \leq t$\\
		$\implies i \leq t$
	\end{center}
	The above also implies that,
	\begin{equation}
		P(X_{t}=i>t)=0
	\end{equation}
	 Also, setting initial condition of the \textit{random walk} gives,
	 \begin{equation}
	  	P(X_{t}=0)=1
	 \end{equation}
	 We introduce some more notations, let $\alpha_{ t}$ denote the total number of $+1$ and $\beta_{ t}$ denote the total number of $-1$ for a particular $X_{t}$ at time t,\\\smallskip
	 Obviously the following conditions holds,
	 \begin{equation}
	 	\alpha_{ t}+\beta_{ t}=t
	 \end{equation}
	 \begin{equation}
		\alpha_{ t}-\beta_{ t}=X_{t}=i
	 \end{equation}
	 Solving the \textit{equations}  $(11)$ and $(12)$ we have,
	 \begin{equation}
	 	\alpha_{ t} =\dfrac{1}{2}(t+i), \beta_{ t} =\dfrac{1}{2}(t-i)
	 \end{equation}
	 \pagebreak
	 Now, we find the probability given by \textit{equation} $(8)$. We ask ourselves a question, "How many ways are there for $X_{t}$ to be $i$?". The answer is the number of ways in which we can select the number of $\alpha_{ t}$, for that particular $i$, the relation of which is given by \textit{equation} $(13)$. Then we multiply the probabilities of having that number of $1$s as in binomial distribution. \\\bigskip
	 \begin{equation}
	 	\boxed{P(X_{t}=i)=\Comb{n}{\frac{1}{2}(t+i)}p^{\frac{1}{2}(t+i)}q^{\frac{1}{2}(t-i)}=\Comb{n}{\alpha_{t}}p^{\alpha_{t}}q^{\beta_{t}}}
	 \end{equation}
	 \subsection{Mean}
	 \begin{flushleft}
	 	Before we find mean of $X_{t}$, we need to find the mean of $Y_{i}$, we know that it is independent identically distributed random variable as mentioned before,\\\smallskip
	 	The formula of mean is given by,
	 	\begin{equation}
	 		\mu_{Y}=E(Y)=\Sigma x_{k}p_{Y}(x_{k})
	 	\end{equation}
	 	where, in above formula $p_{Y}(x_{k})$ is probability of $Y=x_{k}$.\\\smallskip
	 	The \textit{mean}, or \textit{expectation} of $Y_{i}$ is given by,
	 	\begin{equation}
	 		E(Y_{i})=\Sigma x_{k}p_{Y_{i}}(x_{k})
	 	\end{equation}
	 	The probabilities and corresponding values are given by \textit{equation} $(4)$,
	 	\begin{equation}
	 		E(Y_{i})=(1)(p)+(-1)(q)=p-q
	 	\end{equation}
	 	Now, we have sufficient set-up to derive the mean of $X_{t}$,
	 	\begin{equation}
	 		E(X_{t}) = E( \sum_{\mathclap{i=1}}^{t} Y_{i})
	 	\end{equation}
	 	Since all the $Y_{i}$'s are independent and identical, we can write the above equation as,
	 	\begin{equation}
	 		E(X_{t}) = tE(Y_{i})
	 	\end{equation}
	 	From \textit{equation} (17),
	 	\begin{equation}
	 		\boxed{E(X_{t})=t(p-q)}
	 	\end{equation}
	 \end{flushleft}
 	\subsection{Variance}
 	\begin{flushleft}
 		Before we find variance of $X_{t}$, we need to find the variance of $Y_{i}$,\\\smallskip
 		Before we calculate the variance of $Y_{i}$ we need to calculate $E(Y^{2})$,
 		\begin{equation}
 		E(Y^{2})=\Sigma x_{k}^{2}p_{Y}(x_{k})
 		\end{equation}
 		where, in above formula $p_{Y}(x_{k})$ is probability of $Y=x_{k}$.\\\smallskip
 		\begin{equation}
 		\implies E(Y_{i}^{2})=\Sigma x_{k}^{2}p_{Y_{i}}(x_{k})
 		\end{equation}
 		The probabilities and corresponding values are given by \textit{equation} $(4)$,
 		\begin{equation}
 		\implies E(Y_{i}^{2})=(1)^{2}(p)+(-1)^{2}(q)=p+q=1
 		\end{equation}
 		Now, we have sufficient set-up to derive the variance of $Y_{i}$,
 		\begin{equation}
 		Var(Y_{i}) = E(Y_{i}^{2})-[E(Y_{i})]^{2}
 		\end{equation}
 		Putting the values of $E(Y_{i}^{2})$ and $E(Y_{i})$ from \textit{equation} $(23)$ and $(17)$ we have,
 		\begin{center}
 			$\implies Var(Y_{i}) = 1-(p-q)^{2}$\\\smallskip
 			$\implies Var(Y_{i}) = 1-[(p+q)^{2}-4pq]$\\\smallskip
 			$\implies Var(Y_{i}) = 1-[1-4pq]$\\\smallskip
 			$\implies Var(Y_{i}) = 4pq$
 		\end{center}
 		\begin{equation}
 			 \boxed{ Var(Y_{i}) = 4pq }
 		\end{equation}
 		We can now come up with variance with $X_{t}$, given by,
 		\begin{equation}
 			Var(X_{t})=Var(\sum_{\mathclap{i=1}}^{t} Y_{i})
 		\end{equation}
 		Using the property of variance that $Var(A+B) = Var(A) + Var(B)$, also keeping in mind the fact that $Y_{i}$ is independent identically distributed random variable we have,
 		\begin{equation}
 			Var(X_{t})=tVar(Y_{i})
 		\end{equation}
 		Using \textit{equation} $(25)$ we have,
 		\begin{equation}
 			\boxed{Var(X_{t})=4tpq}
 		\end{equation}
 	\end{flushleft}
 	\subsection{Auto-correlation function}
 	The auto-correlation function for the two parameters $t$ and $s$ is given by,
 	\begin{center}
 		$R_{X}(t,s) = E[X_{t}X_{s}]$\\\smallskip
 	\end{center}
 	\begin{equation}
 		\implies R_{X}(t,s) = E[\sum_{\mathclap{i=1}}^{t} Y_{i} \sum_{\mathclap{j=1}}^{s} Y_{j}]
 	\end{equation}
 	Using properties of expectation we have,
 	\begin{equation}
 	\implies R_{X}(t,s) = \sum_{\mathclap{i=1}}^{t} \sum_{\mathclap{j=1}}^{s} E[Y_{i}  Y_{j}]
 	\end{equation}
 	Using some basic rules and principle it can be shown that the above is equal to,
 	\begin{equation}
 	\implies R_{X}(t,s) =\sum_{\mathclap{i=1}}^{min(t,s)} E[Y_{i}^{2}]  + \sum_{\mathclap{i=1}}^{t} \sum_{\substack{\mathclap{j=1}\\\mathclap{i\neq j}}}^{s} E[Y_{i}][ Y_{j}]
 	\end{equation}
 	Using \textit{equations} $(17)$ and $(23)$ and using \textit{inclusion-exclusion} principle we have,\\\smallskip
 	\begin{equation}
 	\implies \boxed{R_{X}(t,s) =min(t,s)  +[ts-min(t,s)](p-q)^{2}}
 	\end{equation}
 	\\\smallskip
 	For a special case when, $p=q=\dfrac{1}{2}$ we have,
 	\begin{center}
 		$R_{X}(t,s) =min(t,s)$
 	\end{center}
 	\pagebreak
 	\subsection{Auto-covariance function}
 	The auto-covariance function for the two parameters $t$ and $s$ is given by,
 	\begin{equation}
 		K_{X}(t,s) = R_{X}(t,s)-\mu_{X}(t)\mu_{X}(s)
 	\end{equation}
 	Using \textit{equations} $(20)$ and $(32)$ we have,
 	\begin{equation}
 		K_{X}(t,s) = min(t,s)  +[ts-min(t,s)](p-q)^{2}-ts(p-q)^{2}
 	\end{equation}
 	Solving the above equation we have,
 	\begin{equation}
 		\boxed{K_{X}(t,s) = min(t,s)[1-(p-q)^{2}]}
 	\end{equation}
 	\section{Proving Random Walk is a Markov Chain}
 	From \textit{equation} $(3)$ we have,
 	\begin{center}
 	$X_{t} = \sum_{{i=1}}^{t} Y_{i}\enspace , \enspace X_{0}=0\enspace ,\enspace t \geq 1$ 
 	\end{center}
 	Moreover $t$ takes discrete values,
 	\begin{center}
 		$t \in \{1,2,3,...\}$
 	\end{center}
 	By definition a discrete time parameter \textit{Markov Chain} is characterized by the following equation,
 	\begin{equation}
 		P(X_{t+1}=i_{t+1}|X_{t}=i_{t},X_{t-1}=i_{t-1},...,X_{0}=i_{0})=P(X_{t+1}=i_{t+1}|X_{t}=i_{t})
 	\end{equation}
 	The above equation clearly indicates that in a Markov chain the future state depends solely on the current state, irrespective of all the past state. It will not be accurate to say that it does not depend on the past, but it will be more theoretically correct to say that all the past information is characterized or condensed in current state. To prove that \textit{Random Walk} $X_{t}$ is indeed a Markov Chain we use a recursive function we already defined in \textit{equation} $(7)$,
 	\begin{center}
 		$X_{t}=Y_{t}+X_{t-1}$
 	\end{center}
 	From above equation we can clearly see that it only summation of two terms, $Y_{t}$ is independent random variable, and $X_{t-1}$. This, shows that $X_{t}$ only depends only upon the previous value \textit{i.e.,} $X_{t-1}$. This completes our proof.
 	\section{One-step transition probability}
 	The one step transition probability by definition is given by,
 	\begin{equation}
 		p_{ji}=P(X_{t}=i|X_{t-1}=j)=
 		\begin{cases}
 		p,& i=j+1\\
 		q,& i=j-1 \\
 		0,&\text{otherwise}
 		\end{cases}
 	\end{equation}
 	\begin{flushleft}
 		Moreover, $p+q=1$,\\\smallskip
 		The above equations means that if the previous state was $j$ then the next state, depending upon probability could be $j+1$ or $j-1$.\\\smallskip
 		Also, if we are to have a transition probability matrix the state space has to be finite.
 	\end{flushleft}
 	\pagebreak
 	\section{Applications}
 	The following are some of the applications of \textit{random walk} in practical scenarios:
 	\begin{itemize}
 		\item{The concept of \textit{simple random walk} is used in \textit{'physics'} where, the physical movement of particles as in \textit{'Brownian motion'} is modeled.Also, of \textit{molecules} of liquids and gases.}
 		\item{In subjects such as \textit{'economics'}, the \textit{random walk} is used to model share prices and other factors.}
 		\item{In Computer Science, \textit{random walks} are used to estimate the size of World Wide Web.}
 	\end{itemize}
 	These are applications only to mention a few. Next we will be discussing the \textit{Gambler's Ruin Problem}.
 	\section{Gambler's Ruin Problem}
 	\begin{flushleft}
 		Let us assume that there are two gamblers, $G_1$ and $G_2$, also, let the gambler $G_1$ has $m_1$ and $G_2$ has $m_2$ rupees.\\\bigskip
 		The rules of games go like this:"$G_1$ wins $1$ rupees and $G_2$ loses $1$ rupees with probability $p$ and $G_1$ loses $1$ rupees and $G_2$ wins $1$ rupees with probability $q$. They play until one of them goes broke!"\\\bigskip
 		The total capital money combining the two players is $M=m_1+m_2$.\\\bigskip
 		Also, let $Y_{i}$ be independent identically distributed random variables, we have,
 		\begin{equation}
 		P(Y_{i}=1) = p
 		\end{equation}
 		\begin{equation}
 		P(Y_{i}=-1) = q 
 		\end{equation}
 		Also, $p+q=1$ and $i \geq 1$\\\bigskip
 		Let $X_{t}$ be the amount of money the gambler $G_1$ has at time $t$. This quantity can be represented as:
 		\begin{equation}
 		X_{t} = \sum_{\mathclap{i=1}}^{t} Y_{i}\enspace , \enspace X_{0}=0
 		\end{equation}
 		The above equation can be recursively defined as follows:
 		\begin{center}
 			$ X_{t}=Y_{t}+X_{t-1}$
 		\end{center}
 		The above is a similar recursive equation as given by \textit{equation} $(7)$, except that 
 		here we have \textit{terminating} or \textit{absorbing} states $X_t=M$ or $X_t=0$, which means that the game terminates when any one of these conditions gets satisfied.\\\bigskip
 		In the previous section we have already discussed the criteria for a random process to be a Markov Chain. So, form the \textbf{Section} 3, we infer that this process is Markov chain with a discrete \textit{finite} state space contrary to the one defined by \textit{equation} $(5)$. The finite state space can be represented as follows,
 		\begin{equation}
 			S=\{0,1,2,...,M\}
 		\end{equation}
 		Additionally, this process has has absorbing states.\\\bigskip
 		This Markov Chain $X_{t}$ is also known as \textit{simple random walk with absorbing states}.\\\bigskip
 		We define the transition probabilities with respect to the conditions mentioned above,\\\smallskip
 		\begin{center}
 			$p_{i,i+1}=P(X_{t}=i+1|X_{t-1}=i)=p$\\\smallskip
 			$p_{i,i-1}=P(X_{t}=i-1|X_{t-1}=i)=q$\\\smallskip
 			$p_{i,i}=P(X_{t}=i|X_{t-1}=i)=0$\\\smallskip
 			$p_{0,0}=P(X_{t}=0|X_{t-1}=0)=1$\\\smallskip
 			$p_{M,M}=P(X_{t}=M|X_{t-1}=M)=1$\\\smallskip
 		\end{center}
 		Since the given state space is finite we can draw a \textit{generalized transition probability matrix}.\\\bigskip
 		A general matrix can be defined as follows:
 		\[
 		P = \kbordermatrix{
 			& 0 & 1 & 2 & 3 & \dots & M-2 & M-1 & M\\
 			0 & 1 & 0 & 0 & 0 & \dots & 0 & 0 & 0\\
 			1 & q & 0 & p & 0 & \dots & 0 & 0 & 0\\
 			2 & 0 & q & 0 & p & \dots & 0 & 0 & 0\\
 			\vdots & \vdots & \vdots & \vdots & \vdots & \dots & \vdots & \vdots & \vdots\\
 			M-1 & 0 & 0 & 0 & 0 & \dots & q & 0 & p \\
 			M & 0 & 0 & 0 & 0 & \dots & 0 & 0 & 1
 		}
 		\]
 		The matrix $P$ defined as above is the transition probability matrix with the vertical marking row-wise indicates the initial state and the horizontal markings at the top of the matrix indicates the next state corresponding to the current state.\\\bigskip
 		The matrix is solely filled with the transitions already shown.
 		\subsection{Example}
 		As an example we can think that,"Two friends Tom and Jim play a game. Tom has initially $20$ rupees and Jim has $15$. They play a game. They start tossing a coin. If heads appear Tom wins $1$ rupees else he loses $1$ and Jim wins $1$ and vice-versa. This game continues until Tom has all the money or say capital money of $35$ rupees or goes broke for $0$ rupees!"\\\bigskip
 		Also, it is worth noting that in \textit{Casinos}, the probability of players winning a game is biased. This, is because the \textit{Casino} also needs to make profit and if it would have been unbiased then they would not make any profit at all. So, finite mathematics comes into play!
 		\subsection{Probability of Ruin and Win}
 		Taking a general example for Gambling, let us denote $P(X_{0}=i)$ be the probability that gambler say $G_1$ (\textit{as in the general example given in the start of this section}) goes broke, \textit{i.e.,} loses all his money when initially he has \textit{i} rupees. Also, it has finite discrete state space like the one given by \textit{equation} $(41)$. \\\smallskip
 		We can also say that, since this kind of random process has two absorbing state, namely $X_{t}=0$ and $X_{t}=M$, the defined $P(X_{0}=i)$ is the probability for absorption at state $X_{t}=0$.\\\smallskip
 		Also, let the probability of transition be as defined by \textit{equation} $(38)$ and $(39)$ \textit{i.e.,} gaining $1$ rupees has probability of $p$ and losing has probability of $q$. We can now define a recursive function for the same. Now for $i \in (0,M)$ we have the following recurrence relation,\\\smallskip
 		\begin{equation}
 			P(X_{0}=i)=pP(X_{1}=i+1)+qP(X_{1}=i-1)
 		\end{equation}
 		For simplicity we can write the above for general time $t$ as,
 		\begin{equation}
 			P(i)=pP(i+1)+qP(i-1)
 		\end{equation}
 		The states above can be read as,for the first term the "Gambler $G_1$ wins first round and subsequently in future loses all the money he had initially", the second term "Gambler $G_1$ loses first round and subsequently in future loses all the money he had initially".\\\smallskip
 		Rearranging the equation we have,
 		\begin{equation}
 			P(i+1)-\dfrac{1}{p}P(i)+\dfrac{q}{p}P(i-1)=0\enspace,\enspace i \in (0,M)
 		\end{equation}
 		By the construct of the problem we have, $P(0)=1$ and $P(M)=0$. \textit{equation} is a homogeneous linear constant coefficient difference equation, using the following identity that $P(i+1)=\lambda P(i)$ and recursively implementing it we get,\\\smallskip
 		\begin{equation}
 		\lambda^{i+1}-\dfrac{1}{p}\lambda^{i}+\dfrac{q}{p}\lambda^{i-1}=0\enspace,\enspace p+q=1
 		\end{equation}
 		\begin{equation}
 		\lambda^{2}-\dfrac{1}{p}\lambda+\dfrac{q}{p}=(\lambda-1)(\lambda-\dfrac{q}{p})=0
 		\end{equation}
 		The above equation gives us the following solutions: $\lambda_1=1$ and $\lambda_2=\dfrac{q}{p}$. The general solution of this difference equation is given by,
 		\begin{equation}
 			P(i)=k_1 \lambda_1^{i} + k_2 \lambda_2^{i}\enspace , \enspace p \neq q 
 		\end{equation}
 		Plugging the values of $\lambda_1$ and $\lambda_2$ in the above equation we have,
 		\begin{equation}
 		P(i)=k_1 + k_2 (\dfrac{q}{p})^{i}\enspace , \enspace p \neq q 
 		\end{equation}
 		In the above equation $k_1$ and $k_2$ are arbitrary constants. Using the absorbing conditions we have,
 		\begin{center}
 			$k_1 + k_2 = 1$\\\smallskip
 			$k_1 + k_2(\dfrac{q}{p})^{M} = 0$
 		\end{center}
 		Solving the above two equations we have the values of $k_1$ and $k_2$ as,
 		\begin{center}
 			$k_1=\dfrac{-(\frac{q}{p})^{M}}{1-(\frac{q}{p})^{M}}$\\\smallskip
 			$k_2=\dfrac{1}{1-(\frac{q}{p})^{M}}$
 		\end{center}
 		Plugging the values of $k_1$ and $k_2$ in \textit{equation} we have,
 		\begin{equation}
 			\boxed{P(i)=\dfrac{(\frac{q}{p})^{i}-(\frac{q}{p})^{M}}{1-(\frac{q}{p})^{M}} \enspace, \enspace p \neq q}
 		\end{equation}
 		For very large values of $M$ we can assume that $M \rightarrow \infty$ then, based on whether $p<q$ or $p>q$, we have,
 		\begin{equation}
 		P(i)=
 		\begin{cases}
 		1,& p<q\\
 		(\frac{q}{p})^{i},& p>q
 		\end{cases}
 		\end{equation}
 		For the special case when $p=q$, let $\lambda = \frac{q}{p}$, then \textit{equation}, $(49)$ turns out to be,
 		\begin{center}
 			$P(i)=\dfrac{\lambda^{i}-\lambda^{M}}{1-\lambda^{M}}$
 		\end{center}
 		So, in the above $\lambda \rightarrow 1$. We can see that the equation above is of the form $\frac{0}{0}$. Hence, we can apply L'Hôpital's rule to the above we have,
 		\begin{center}
 			$P(i)=\dfrac{i\lambda^{i-1}-M\lambda^{M-1}}{-M\lambda^{M-1}}$
 		\end{center}
 		Plugging in the value of $\lambda=1$ in above we have,
 		 \begin{center}
 		 	$P(i)=\dfrac{i-M}{-M}$
 		 \end{center}
 	 	\begin{equation}
 	 		\boxed{P(i)=1-\dfrac{i}{M}}
 	 	\end{equation}
 	 	Therefore, above is the answer for the special case when $p=q=\frac{1}{2}$.\\\smallskip
 	 	We now to find the probability of gambler $G_1$ winning if he has $i$ rupees initially the answer is,
 	 	\begin{equation}
 	 		P'(i)=1-P(i)=\boxed{P(i)=\dfrac{1-(\frac{q}{p})^{i}}{1-(\frac{q}{p})^{M}}}
 	 	\end{equation}
 	 	For very large values of $M$ we can assume that $M \rightarrow \infty$ then, based on whether $p<q$ or $p>q$, we have,
 	 	\begin{equation}
 	 	P(i)=
 	 	\begin{cases}
 	 	0,& p<q\\
 	 	1-(\frac{q}{p})^{i},& p>q
 	 	\end{cases}
 	 	\end{equation}
 	 	For special case of $p=q=\frac{1}{2}$ we have,
 	 	\begin{equation}
 	 	\boxed{P(i)=\dfrac{i}{M}}
 	 	\end{equation}
 	 	To summarize, the probability of gambler $G_1$ with $i$ amount of money initially and losing all the money is given by \textit{equation} $(49)$ together with special cases as described by \textit{equations} $(50)$ and $(51)$, for winning the corresponding equations are given by \textit{equation} $(52), (53), (54)$.
 	 	\pagebreak
 	\end{flushleft}
 	\section{Conclusion}
 	\begin{flushleft}
 		\fontsize{12pt}{18pt}\selectfont
 		Starting with the introduction we have discussed the random process and how the random walk develops. We have seen the graphical construct of the \textit{random walk}, taking some examples.\\\smallskip
 		We saw the probability distribution of the random walk along with mean, variance, auto-correlation function, auto-covariance function and also seen the one-step transition probabilities.\\\smallskip
 		We tried to understand why random walk is a Markov Chain, we have seen the recursive function and the dependency and relation among states and why it turns out to be Markov.\\\smallskip
 		We have seen some applications of random process in particular \textit{random walk} and in the end we have seen the 'Gambler's ruin problem' very concisely described with comprehensive mathematical analysis and discussed with some examples. We have also seen the probability of winning and losing with derivations of the corresponding equations.
 	\pagebreak
 \end{flushleft}
 	\begin{thebibliography}{9}
 		\bibitem{to}
 		\texttt{https://en.wikipedia.org/wiki/Random\_walk}
 		
 		\bibitem{too}
 		\texttt{https://en.wikipedia.org/wiki/Stochastic\_process}
 		
 		\bibitem{toooo}
 		Random Variables and Random Processes, Schaum's Outline
 		
 		\bibitem{tooo}
 		\texttt{http://www.columbia.edu/\texttildelow ks20/FE-Notes/4700-07-Notes-GR.pdf}
 		
 		\bibitem{tooooo}
 		Stochastic Process-1,(MIT)
 		\texttt{https://www.youtube.com/watch?v=TuTmC8aOQJE\&t=3322s}
 		
 		\bibitem{tooooo}
 		Gambler's Ruin, Brendon Foltz
 		\texttt{https://www.youtube.com/watch?v=afIhgiHVnj0}
 	\end{thebibliography}
 	
\end{document}